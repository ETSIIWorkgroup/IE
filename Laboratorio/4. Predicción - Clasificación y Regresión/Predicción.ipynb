{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicción\n",
    "**Autores:** José A. Troyano, Beatriz Pontes &nbsp;&nbsp;&nbsp; **Última modificación:** 10/03/2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------\n",
    "## Contenido\n",
    "\n",
    "1. <a href=\"#entrenamiento_clf\"> Entrenamiento de un clasificador </a> <br>\n",
    "    1.1. <a href=\"#reg_log\"> ¿Qué es la regresión logística? ¿Es regresión o clasificación? </a> <br>\n",
    "    1.2. <a href=\"#estimador_reg_log\"> El estimador _LogisticRegression_ </a>  <br>\n",
    "2. <a href=\"#metricas_clf\"> Métricas de evaluación de clasificadores </a> <br>\n",
    "    2.1. <a href=\"#confusion\"> Matriz de confusión: TP, FP, TN, FN </a> <br>\n",
    "    2.2. <a href=\"#pcf1\"> Precisión, cobertura y f1 </a> <br>\n",
    "    2.3.  <a href=\"#clasificadores\"> Experimentos de clasificación </a> <br>\n",
    "    \n",
    "3. <a href=\"#entrenamiento_reg\"> Entrenamiento de un regresor  </a> <br>\n",
    "    3.1. <a href=\"#regresion_lineal\"> Regresión lineal </a><br>\n",
    "    3.2. <a href=\"#estimador_reg_lin\"> El estimador _LinearRegression_ </a> <br>\n",
    "4. <a href=\"#metricas_reg\"> Métricas de evaluación de regresores </a> <br>\n",
    "    4.1. <a href=\"#r2\"> Coeficiente r2 </a> <br>\n",
    "    4.2. <a href=\"#mae\"> MAE </a> <br>\n",
    "    4.3. <a href=\"#regresores\"> Experimentos de regresión  </a> <br>\n",
    "------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este notebook veremos cómo entrenar un estimador de sklearn y distintas formas de evaluar la calidad del modelo obtenido. Trabajaremos con clasificadores (predicción de un atributo discreto) y regresores (predicción de un atributo numérico). \n",
    "\n",
    "Empezaremos por importar todos los elementos que usaremos a lo largo del notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Numpy, scipy y pandas\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import pandas as pd\n",
    "\n",
    "# Datasets\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Evaluación\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, cross_val_score, learning_curve\n",
    "\n",
    "# Visualización\n",
    "import seaborn as sns\n",
    "from pySankey import sankey     # pip install pySankey\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Entrenamiento de un clasificador <a name=\"entrenamiento_clf\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos el dataset _breast cancer_, disponible en el repositorio UCI y también incluido en el conjunto de datasets de prueba de Sklearn. \n",
    "\n",
    "El dataset contiene 569 registros correspondientes a pacientes de cáncer de mama. Los atributos se corresponden con métricas calculadas sobre las células identificadas en imágenes de biopsias. Para cada paciente se realizan 10 métricas sobre varias células, y para cada métrica se registran la media, desviación estándar y peor resultado de todos valores. La clase a predecir es $0$ ó $1$ en función de que el tumor sea maligo o no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: acceder al dataset disponible en sklearn y crear el dataframe 'X' para los atributos, y la serie 'y' para la clase\n",
    "#    - Mostrar información sobre las columnas\n",
    "#    - Mostrar con una gráfica la distribución de los valores de la clase\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenar un clasificador es muy simple en Sklearn. Basta con crear un objeto del estimador que queramos entrenar y ejecutar el método <code>fit</code>. En este notebook usaremos uno de los clasificadores que mejor resultado suele dar de los disponibles en Sklearn: <code>LogisticRegression</code>. \n",
    "\n",
    "### 1.1. ¿Qué es la regresión logística? ¿Es regresión o clasificación? <a name=\"reg_log\"> </a>\n",
    "\n",
    "Es una técnica que se usa para predecir el resultado de una variable discreta, es por tanto una _técnica de clasificación_. En su formulación más simple (la binaria) se aprende a estimar la probabilidad de que una instancia pertenezca a la clase positiva de la siguiente forma:\n",
    "- Probabilidades cercanas a $1$ darán lugar a clasificar la instancia como de la clase positiva\n",
    "- Probabilidades cercanas a $0$ darán lugar a clasificar la instancia como de la clase negativa\n",
    "\n",
    "\n",
    "\n",
    "El modelo logístico establece la siguiente relación entre la probabilidad de pertenecer a la clase positiva y los valores de los atributos de la instancia $X$:\n",
    "\n",
    "$$\n",
    "P(X) = P(y=1\\;| \\;x_1, x_2, ..., x_n)  = \\frac{1}{1+exp(-\\alpha-\\beta_1x_1-\\beta_2x_2...-\\beta_nx_n)}\n",
    "$$\n",
    "\n",
    "A este tipo de funciones se les denomina _logísticas_ (de ahí el nombre _regresión logística_).\n",
    "\n",
    "Se puede generalizar a una clasificación no binaria (con $k$ categorías) mediante la construcción de $k-1$ clasificadores binarios.\n",
    "\n",
    "La función _logit_ nos permite convertir el problema de estimar la probablilidad en un problema de regresión lineal. Esta es la función _logit_:\n",
    "$$\n",
    "logit(p) = ln(\\frac{p}{1-p})\n",
    "$$\n",
    "\n",
    "Y mediante una serie de transformaciones se demuestra que:\n",
    "\n",
    "$$\n",
    "logit(P(y=1\\;| \\;x_1, x_2, ..., x_n)) = \\alpha+\\beta_1x_1+\\beta_2x_2...+\\beta_nx_n\n",
    "$$\n",
    "\n",
    "Gracias a usar la función _logit_ como función de enlace se consigue una formulación lineal del problema, lo que permite la aplicación de técnicas de regresión lineal (de ahí el nombre _regresión_ logística)  para el aprendizaje de los coeficientes $\\alpha$ y $\\beta_i$.\n",
    "\n",
    "\n",
    "\n",
    "### 1.2. El estimador <code>LogisticRegression</code> <a name=\"estimador_reg_log\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1 Entrenamiento con el conjunto de datos completo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: crear un estimador de la clase LogisticRegression y entrenarlo con el dataset <X,y>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez entrenado un clasificador, podemos usarlo para predecir la clase de un conjunto de instancias con el método <code>predict</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: predecir la salida de los primeros 10 valores de X con el clasificador entrenado anteriormente\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2 Separación en conjuntos de entrenamiento y validación "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: dividir el dataset <X, y> en dos datasets <X_train, y_train> y <X_test, y_test> con una distribución 80%-20%,\n",
    "#            entrenar el clasificador con <X_train, y_train> y calcular la métrica accuracy con <X_test, y_test>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez entrenado un clasificador, podemos usarlo para predecir la clase de un conjunto de instancias con el método <code>predict</code>. Muchos estimadores nos proporcionan también las probabilidades de cada una de las clases gracias al método <code>predict_proba</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: calcular las probabilidades de cada clase para las instancias de X_test y guardarlas en y_test_proba\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos observar aparecen dos probabilidades para cada fila: la probabilidad de elegir la clase $0$ y la probabilidad de elegir la clase $1$. Un análisis de la distribución de estas probabilidades, nos dará pistas sobre si el conjunto de datos a clasificar está _bien separado_. Si es así, habrá pocos casos dudosos al clasificador le costará menos trabajo decidir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: mostrar con un histograma la distribución de la probabilidad de pertenecer a la clase 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.3 Entrenamiento y evaluación mediante validación cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos aplicar validación cruzada para evaluar. Por defecto la métrica de evaluación es <code>accuracy_score</code> aunque, como veremos en la siguiente sección, hay más métricas implementadas en Sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: predecir la salida de todas las instancias mediante validación cruzada y guardar las prediccciones en y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: calcular el score por defecto sobre todas las instancias mediante validación cruzada\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: calcular las probabilidades de cada clase para todas las instancias y guardarlas en y_pred_prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: mostrar con un histograma la distribución de la probabilidad de pertenecer a la clase 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Métricas de evaluación <a name=\"metricas_clf\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de esta sección trabajaremos sobre los resultados de la validación cruzada (mediante las series <code>y</code> e <code>y_pred</code>) aunque el análisis podía haberse hecho perfectamente con una evaluación _train/test_.\n",
    "\n",
    "En el siguiente enlace se puede consultar la evaluación de modelos en sklearn:\n",
    "https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "\n",
    "### 2.1. Matriz de confusión: TP, FP, TN, FN <a name=\"confusion\"> </a>\n",
    "\n",
    "La matriz de confusión muestra el número de veces que se han producido los distintos tipos de aciertos y fallos. En una clasificación binaria tiene cuatro celdas que suelen denominarse con los siguientes nombres:\n",
    "- TP: _true positives_\n",
    "- TN: _true negatives_\n",
    "- FP: _false positives_\n",
    "- FN: _false negatives_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: crear la matriz de confusión a partir de 'y' e 'y_pred' en un DataFrame con esta estructura:\n",
    "#   - Columnas: [Predicted 0, Predicted 1]\n",
    "#   - Índice: [True 0,True 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: mostrar la matriz de confusión mediante un mapa de calor de Seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: calcular TP, FP, TN y FN a partir de la matriz de confusión anterior\n",
    "#cm = metrics.confusion_matrix(y, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una de las métricas más usadas es el _accuracy_ que mide directamente el porcentaje de aciertos. Si el dataset está balanceado es un buen indicador, pero si alguna de las clases es muy mayoritaria (o minoritaria) la información que nos dá la métrica puede ser bastante engañosa. En las siguientes secciones veremos otras métricas que son menos sensibles a datasets mal balanceados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Precisión, cobertura y f1 <a name=\"pcf1\"> </a>\n",
    "\n",
    "El siguiente paquete de métricas es el formado por la precisión, cobertura (_recall_) y medida f1. Son métricas que dan diferente importancia al tipo de error (p.e. falsos positivos o falsos negativos en clasificación binaria). Pueden ser de utilidad para sistemas en los que nos preocupan más unos errores que otros: por ejemplo, es menos grave dejar pasar un correo _spam_ que eliminar un correo correcto. El significado intuitivo de las métricas es el siguiente:\n",
    "- _precision_: grado de acierto en las instancias propuestas como positivas (¿son todos los que están?)\n",
    "- _recall_: porcentaje de recuperación del total de las instancias positivas (¿están todos los que son?)\n",
    "- _f1_ : media armónica de precisión y cobertura.\n",
    "\n",
    "Al combinar dos métricas complementarias, la medida _f1_ es apropiada para datasets que no estén bien balanceados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: calcular la medida 'precisión' a partir de 'y' e 'y_pred'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: calcular la medida 'cobertura' a partir de 'y' e 'y_pred'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: calcular la medida 'f1' a partir de 'y' e 'y_pred'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Experimentos de clasificación <a name=\"clasificadores\"> </a>\n",
    "\n",
    "En esta sección veremos algunas técnicas más de clasificación de la oferta de sklearn. Para comparar los distintos métodos, almacenaremos los resultados en el siguiente dataframe con tres columnas, dos de ellas serán métricas (_accuracy_ y _f1_) y la última el tiempo de ejecución:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame donde iremos guardando los resultados de los experimentos\n",
    "RESULTADOS_CLF = pd.DataFrame(columns=['ACCURACY', 'F1', 'TIEMPO'])\n",
    "RESULTADOS_CLF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: implementar la función 'experimento_clf' que encapsule todos los pasos de un experimento de clasificación\n",
    "#    PARÁMETROS DE ENTRADA:\n",
    "#       - clasificador: estimador usado en el experimento\n",
    "#       - X: matriz de atributos\n",
    "#       - y: vector de salida\n",
    "#    SALIDAS:\n",
    "#       - Tupla (accuracy, f1, roc-auc, tiempo) con las métricas del experimento y el tiempo invertido en segundos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: usar la función 'experimento_clasificacion' con los siguientes clasificadores y almacenar los resultados \n",
    "#            en el dataframe RESULTADOS_CLF:\n",
    "# - Regresión logística\n",
    "# - Vecinos más cercanos, con k=3\n",
    "# - Árbol de decisión\n",
    "# - Gradient boosting\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Entrenamiento de un regresor <a name=\"entrenamiento_reg\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos el dataset _concrete_, disponible en el repositorio UCI. El dataset contiene 1030 registros correspondientes a medidas de resistencia de hormigón. Los atributos se corresponden con las proporciones de la mezcla distintas muestras de hormigón y la edad (en días) de la muestra. La variable numérica a predecir es la resistencia de cada muestra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: leer el fichero 'concrete.csv' y crear el dataframe 'X' para los atributos, y la serie 'y' para la clase (atributo 'Concrete compressive strength')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenar un regresor es muy simple en Sklearn, basta con crear un objeto del estimador que queramos entrenar y ejecutar el método <code>fit</code>. En este notebook usaremos uno de los regresores más comunes: <code>LinearRegression</code>.\n",
    "\n",
    "### 3.1 ¿Qué es la regresión lineal? <a name=\"regresion_lineal\"> </a>\n",
    "\n",
    "Es un modelo matemático usado para aproximar la relación entre una variable dependiente $y$, y las variables independientes $x_i$. El modelo se expresa con la siguiente fórmula:\n",
    "\n",
    "$$\n",
    "y \\approx \\alpha+\\beta_1x_1+\\beta_2x_2...+\\beta_nx_n\n",
    "$$\n",
    "\n",
    "Sklearn proporciona distinos métodos para realizar regresión lineal. El más simple de ellos es el de los _mínimos cuadrados_ que es el que implementa el estimador <code>LinearRegression</code>. La técnica de los mínimos cuadrados se utiliza para determinar los coeficientes de una función de regresión que minimicen la suma de los cuadrados de los errores. Para una función de regresión lineal, se trataría de minimizar esta expresión:\n",
    "\n",
    "$$\n",
    "S = \\sum (y - f(X))^2 = \\sum (y - \\alpha+\\beta_1x_1+\\beta_2x_2...+\\beta_nx_n)^2\n",
    "$$\n",
    "\n",
    "\n",
    "### 3.2 El estimador <code>LinearRegression</code> <a name=\"estimador_reg_lin\"> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: crear un estimador de la clase LinearRegression y entrenarlo con el dataset <X,y>\n",
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez entrenado un estimador, podemos usarlo para predecir la clase de un conjunto de instancias con el método <code>predict</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: predecir la salida de los primeros 10 valores de X con el regresor entrenado anteriormente\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: dividir el dataset <X, y> en dos datasets <X_train, y_train> y <X_test, y_test> con una distribución 80%-20%,\n",
    "#            entrenar el regresor con <X_train, y_train> y calcular la métrica r2 con <X_test, y_test>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos aplicar validación cruzada para evaluar. Por defecto la métrica de evaluación es <code>r2_score</code> aunque, como veremos en la siguiente sección, hay más métricas implementadas en Sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: predecir la salida de todas las instancias mediante validación cruzada y guardar las prediccciones en y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: calcular el score por defecto sobre todas las instancias mediante validación cruzada\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Métricas de evaluación <a name=\"metricas_reg\"> </a>\n",
    "\n",
    "En las tareas de clasificación las métricas de evaluación se basan en el número de aciertos de las predicciones. En la regresión, sin embargo, no se puede hablar de aciertos ya que las predicciones son numéricas y es muy improbable predecir exactamente el valor correcto. Lo importante para evaluar un regresor es medir la diferencia entre el valor real y el valor predicho. \n",
    "\n",
    "En el siguiente enlace se puede consultar la evaluación de modelos en sklearn:\n",
    "https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "\n",
    "### 4.1. Coeficiente r2 <a name=\"r2\"> </a>\n",
    "R2, o también conocido como coeficiente de determinación, es un coeficente normalizado (entre $-1$ a $1$) que determina la calidad de un modelo para replicar los resultados obsrevados. Se calcula con la siguiente fórmula: \n",
    "$$\n",
    "R2 = 1 - \\frac{\\sum (y -f(X))^2}{\\sum (\\bar{y} - y)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: dadas los siguientes vectores 'y_real' e 'y_pred' calcular la métrica R2\n",
    "#    y_real = [1,   0.5, 1.5, 0]\n",
    "#    y_pred = [1.5, 0,   1.5,  1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: calcular la métrica  R2 usando 'cross_val_score' y el estimador LinearRegression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. MAE <a name=\"mae\"> </a>\n",
    "\n",
    "En la métrica MAE (_mean absolute error_) el error se calcula con la media de las diferencias absolutas entre los valores observados y las predicciones. Es una métrica lineal que se puede interpretar en términos de la magnitud a predecir. Se calcula con la siguiente fórmula: \n",
    "\n",
    "$$\n",
    "MAE = \\frac{\\sum |\\;y -f(X)\\;|}{n}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: dadas los siguientes vectores 'y_real' e 'y_pred' calcular la métrica MAE\n",
    "#    y_real = [1,   0.5, 1.5, 0]\n",
    "#    y_pred = [1.5, 0,   1.5,  1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: calcular la métrica MAE usando 'cross_val_score' y el estimador LinearRegression\n",
    "# NOTA: los scores de MAE son negativos para que los valores altos se correspondan con mejores resultados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Experimentos de regresión <a name=\"regresores\"> </a>\n",
    "\n",
    "En esta sección veremos algunas técnicas más de regresión de la oferta de sklearn. Para comparar los distintos métodos, almacenaremos los resultados en el siguiente dataframe con tres columnas, dos de ellas serán métricas (_accuracy_ y _f1_) y la última el tiempo de ejecución:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame donde iremos guardando los resultados de los experimentos\n",
    "RESULTADOS_REG = pd.DataFrame(columns=['R2', 'MAE', 'TIEMPO'])\n",
    "RESULTADOS_REG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: implementar la función 'experimento_regresion' que encapsule todos los pasos del experimento de la sección anterior\n",
    "#    PARÁMETROS DE ENTRADA:\n",
    "#       - regresor: estimador usado en el experimento\n",
    "#       - X: matriz de atributos\n",
    "#       - y: vector de salida\n",
    "#    SALIDAS:\n",
    "#       - Devolver la tupla (r2, mae, tiempo) con la puntuación del experimento y el tiempo invertido en segundos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: usar la función 'experimento_regresion' con los siguientes regresores y almacenar los resultados \n",
    "#            en el dataframe RESULTADOS_REG:\n",
    "# - Regresión lineal\n",
    "# - Vecinos más cercanos, con k=3\n",
    "# - Vecinos más cercanos, con k=5\n",
    "# - Árbol de decisión\n",
    "# - Gradient boosting\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
