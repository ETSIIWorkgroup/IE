{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicción\n",
    "**Autores:** José A. Troyano, Beatriz Pontes &nbsp;&nbsp;&nbsp; **Última modificación:** 10/03/2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------\n",
    "## Contenido\n",
    "\n",
    "1. <a href=\"#entrenamiento_clf\"> Entrenamiento de un clasificador </a> <br>\n",
    "    1.1. <a href=\"#reg_log\"> ¿Qué es la regresión logística? ¿Es regresión o clasificación? </a> <br>\n",
    "    1.2. <a href=\"#estimador_reg_log\"> El estimador _LogisticRegression_ </a>  <br>\n",
    "2. <a href=\"#metricas_clf\"> Métricas de evaluación de clasificadores </a> <br>\n",
    "    2.1. <a href=\"#confusion\"> Matriz de confusión: TP, FP, TN, FN </a> <br>\n",
    "    2.2. <a href=\"#pcf1\"> Precisión, cobertura y f1 </a> <br>\n",
    "    2.3.  <a href=\"#clasificadores\"> Experimentos de clasificación </a> <br>\n",
    "    \n",
    "3. <a href=\"#entrenamiento_reg\"> Entrenamiento de un regresor  </a> <br>\n",
    "    3.1. <a href=\"#regresion_lineal\"> Regresión lineal </a><br>\n",
    "    3.2. <a href=\"#estimador_reg_lin\"> El estimador _LinearRegression_ </a> <br>\n",
    "4. <a href=\"#metricas_reg\"> Métricas de evaluación de regresores </a> <br>\n",
    "    4.1. <a href=\"#r2\"> Coeficiente r2 </a> <br>\n",
    "    4.2. <a href=\"#mae\"> MAE </a> <br>\n",
    "    4.3. <a href=\"#regresores\"> Experimentos de regresión  </a> <br>\n",
    "------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este notebook veremos cómo entrenar un estimador de sklearn y distintas formas de evaluar la calidad del modelo obtenido. Trabajaremos con clasificadores (predicción de un atributo discreto) y regresores (predicción de un atributo numérico). \n",
    "\n",
    "Empezaremos por importar todos los elementos que usaremos a lo largo del notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All done!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Numpy, scipy y pandas\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import pandas as pd\n",
    "\n",
    "# Datasets\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Evaluación\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, cross_val_score, learning_curve\n",
    "\n",
    "# Visualización\n",
    "import seaborn as sns\n",
    "from pySankey import sankey     # pip install pySankey\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"All done!\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Entrenamiento de un clasificador <a name=\"entrenamiento_clf\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos el dataset _breast cancer_, disponible en el repositorio UCI y también incluido en el conjunto de datasets de prueba de Sklearn. \n",
    "\n",
    "El dataset contiene 569 registros correspondientes a pacientes de cáncer de mama. Los atributos se corresponden con métricas calculadas sobre las células identificadas en imágenes de biopsias. Para cada paciente se realizan 10 métricas sobre varias células, y para cada métrica se registran la media, desviación estándar y peor resultado de todos valores. La clase a predecir es $0$ ó $1$ en función de que el tumor sea maligo o no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: acceder al dataset disponible en sklearn y crear el dataframe 'X' para los atributos, y la serie 'y' para la clase\n",
    "#    - Mostrar información sobre las columnas\n",
    "#    - Mostrar con una gráfica la distribución de los valores de la clase\n",
    "X, y = load_breast_cancer(return_X_y = True, as_frame = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33           184.60   \n",
       "1                 0.05667  ...         24.99          23.41           158.80   \n",
       "2                 0.05999  ...         23.57          25.53           152.50   \n",
       "3                 0.09744  ...         14.91          26.50            98.87   \n",
       "4                 0.05883  ...         22.54          16.67           152.20   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 30 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   mean radius              569 non-null    float64\n",
      " 1   mean texture             569 non-null    float64\n",
      " 2   mean perimeter           569 non-null    float64\n",
      " 3   mean area                569 non-null    float64\n",
      " 4   mean smoothness          569 non-null    float64\n",
      " 5   mean compactness         569 non-null    float64\n",
      " 6   mean concavity           569 non-null    float64\n",
      " 7   mean concave points      569 non-null    float64\n",
      " 8   mean symmetry            569 non-null    float64\n",
      " 9   mean fractal dimension   569 non-null    float64\n",
      " 10  radius error             569 non-null    float64\n",
      " 11  texture error            569 non-null    float64\n",
      " 12  perimeter error          569 non-null    float64\n",
      " 13  area error               569 non-null    float64\n",
      " 14  smoothness error         569 non-null    float64\n",
      " 15  compactness error        569 non-null    float64\n",
      " 16  concavity error          569 non-null    float64\n",
      " 17  concave points error     569 non-null    float64\n",
      " 18  symmetry error           569 non-null    float64\n",
      " 19  fractal dimension error  569 non-null    float64\n",
      " 20  worst radius             569 non-null    float64\n",
      " 21  worst texture            569 non-null    float64\n",
      " 22  worst perimeter          569 non-null    float64\n",
      " 23  worst area               569 non-null    float64\n",
      " 24  worst smoothness         569 non-null    float64\n",
      " 25  worst compactness        569 non-null    float64\n",
      " 26  worst concavity          569 non-null    float64\n",
      " 27  worst concave points     569 non-null    float64\n",
      " 28  worst symmetry           569 non-null    float64\n",
      " 29  worst fractal dimension  569 non-null    float64\n",
      "dtypes: float64(30)\n",
      "memory usage: 133.5 KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    357\n",
       "0    212\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenar un clasificador es muy simple en Sklearn. Basta con crear un objeto del estimador que queramos entrenar y ejecutar el método <code>fit</code>. En este notebook usaremos uno de los clasificadores que mejor resultado suele dar de los disponibles en Sklearn: <code>LogisticRegression</code>. \n",
    "\n",
    "### 1.1. ¿Qué es la regresión logística? ¿Es regresión o clasificación? <a name=\"reg_log\"> </a>\n",
    "\n",
    "Es una técnica que se usa para predecir el resultado de una variable discreta, es por tanto una _técnica de clasificación_. En su formulación más simple (la binaria) se aprende a estimar la probabilidad de que una instancia pertenezca a la clase positiva de la siguiente forma:\n",
    "- Probabilidades cercanas a $1$ darán lugar a clasificar la instancia como de la clase positiva\n",
    "- Probabilidades cercanas a $0$ darán lugar a clasificar la instancia como de la clase negativa\n",
    "\n",
    "\n",
    "\n",
    "El modelo logístico establece la siguiente relación entre la probabilidad de pertenecer a la clase positiva y los valores de los atributos de la instancia $X$:\n",
    "\n",
    "$$\n",
    "P(X) = P(y=1\\;| \\;x_1, x_2, ..., x_n)  = \\frac{1}{1+exp(-\\alpha-\\beta_1x_1-\\beta_2x_2...-\\beta_nx_n)}\n",
    "$$\n",
    "\n",
    "A este tipo de funciones se les denomina _logísticas_ (de ahí el nombre _regresión logística_).\n",
    "\n",
    "Se puede generalizar a una clasificación no binaria (con $k$ categorías) mediante la construcción de $k-1$ clasificadores binarios.\n",
    "\n",
    "La función _logit_ nos permite convertir el problema de estimar la probablilidad en un problema de regresión lineal. Esta es la función _logit_:\n",
    "$$\n",
    "logit(p) = ln(\\frac{p}{1-p})\n",
    "$$\n",
    "\n",
    "Y mediante una serie de transformaciones se demuestra que:\n",
    "\n",
    "$$\n",
    "logit(P(y=1\\;| \\;x_1, x_2, ..., x_n)) = \\alpha+\\beta_1x_1+\\beta_2x_2...+\\beta_nx_n\n",
    "$$\n",
    "\n",
    "Gracias a usar la función _logit_ como función de enlace se consigue una formulación lineal del problema, lo que permite la aplicación de técnicas de regresión lineal (de ahí el nombre _regresión_ logística)  para el aprendizaje de los coeficientes $\\alpha$ y $\\beta_i$.\n",
    "\n",
    "\n",
    "\n",
    "### 1.2. El estimador <code>LogisticRegression</code> <a name=\"estimador_reg_log\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1 Entrenamiento con el conjunto de datos completo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1. Entrenar el clasificador con X,y.\n",
    "2. Separar X_80, y_80 (para entrenar) y X_20, y_20 (para validar).\n",
    "3. Validación cruzada (porque es un conjunto demasiado pequeño); separando por distintos conjuntos (apartado 2 repetido varias veces).\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(solver='liblinear')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EJERCICIO: crear un estimador de la clase LogisticRegression y entrenarlo con el dataset <X,y>\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Sin el parámetro liblinear necesita más iteraciones, provocaría un fallo.\n",
    "clasificador = LogisticRegression(solver = 'liblinear')\n",
    "clasificador.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez entrenado un clasificador, podemos usarlo para predecir la clase de un conjunto de instancias con el método <code>predict</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 0 0 0 0 0 0]\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "5    0\n",
      "6    0\n",
      "7    0\n",
      "8    0\n",
      "9    0\n",
      "Name: target, dtype: int32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9595782073813708"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EJERCICIO: predecir la salida de los primeros 10 valores de X con el clasificador entrenado anteriormente\n",
    "y_pred = clasificador.predict(X)\n",
    "\n",
    "# Comparar las etiquetas predichas con las reales:\n",
    "print(y_pred[:10])\n",
    "print(y[:10])\n",
    "\n",
    "# Vemos que en el 4º, falla.\n",
    "\n",
    "# Precisión de la predicción:\n",
    "metrics.accuracy_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.2 Separación en conjuntos de entrenamiento y validación "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 0 0 1 0 1 1]\n",
      "305    1\n",
      "511    1\n",
      "386    1\n",
      "527    1\n",
      "11     0\n",
      "265    0\n",
      "536    0\n",
      "512    0\n",
      "428    1\n",
      "375    1\n",
      "Name: target, dtype: int32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9473684210526315"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EJERCICIO: dividir el dataset <X, y> en dos datasets <X_train, y_train> y <X_test, y_test> con una distribución 80%-20%,\n",
    "#            entrenar el clasificador con <X_train, y_train> y calcular la métrica accuracy con <X_test, y_test>\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "\n",
    "# Entrenar \n",
    "clasificador.fit(X_train,y_train)\n",
    "\n",
    "# Validar \n",
    "y_pred_2 = clasificador.predict(X_test)\n",
    "print(y_pred_2[:10])\n",
    "print(y_test[:10])\n",
    "\n",
    "# Precisión:\n",
    "metrics.accuracy_score(y_test, y_pred_2)\n",
    "\n",
    "# Si se ejecuta más veces, se ve que la precisión es poco estable (cambia mucho)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez entrenado un clasificador, podemos usarlo para predecir la clase de un conjunto de instancias con el método <code>predict</code>. Muchos estimadores nos proporcionan también las probabilidades de cada una de las clases gracias al método <code>predict_proba</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.33236441e-03 9.93667636e-01]\n",
      " [1.74774001e-03 9.98252260e-01]\n",
      " [2.59774683e-03 9.97402253e-01]\n",
      " [1.25594803e-03 9.98744052e-01]\n",
      " [9.99989911e-01 1.00893485e-05]\n",
      " [1.00000000e+00 2.50545567e-32]\n",
      " [1.63366543e-01 8.36633457e-01]\n",
      " [9.86610315e-01 1.33896855e-02]\n",
      " [1.67824468e-04 9.99832176e-01]\n",
      " [4.06299492e-03 9.95937005e-01]]\n"
     ]
    }
   ],
   "source": [
    "# EJERCICIO: calcular las probabilidades de cada clase para las instancias de X_test y guardarlas en y_test_proba\n",
    "y_test_prob = clasificador.predict_proba(X_test)\n",
    "print(y_test_prob[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos observar aparecen dos probabilidades para cada fila: la probabilidad de elegir la clase $0$ y la probabilidad de elegir la clase $1$. Un análisis de la distribución de estas probabilidades, nos dará pistas sobre si el conjunto de datos a clasificar está _bien separado_. Si es así, habrá pocos casos dudosos al clasificador le costará menos trabajo decidir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# EJERCICIO: mostrar con un histograma la distribución de la probabilidad de pertenecer a la clase 1\n",
    "y_test_proba_1 = pd.Series(y_test_prob[:, 1])\n",
    "y_test_proba_1.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.3 Entrenamiento y evaluación mediante validación cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos aplicar validación cruzada para evaluar. Por defecto la métrica de evaluación es <code>accuracy_score</code> aunque, como veremos en la siguiente sección, hay más métricas implementadas en Sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 0 0 0 0 0 0]\n",
      "\n",
      "0.9490333919156415\n",
      "\n",
      "[0.94736842 0.9122807  0.92982456 0.94736842 0.96491228 0.96491228\n",
      " 0.94736842 0.94736842 0.96491228 0.96428571]\n",
      "\n",
      "0.9490601503759398\n"
     ]
    }
   ],
   "source": [
    "# EJERCICIO: predecir la salida de todas las instancias mediante validación cruzada y guardar las prediccciones en y_pred\n",
    "y_pred_cross = cross_val_predict(clasificador, X, y, cv = 10)  # cv es el nº de particiones\n",
    "print(y_pred_cross[:10])\n",
    "print(\"\")\n",
    "\n",
    "# Precisión\n",
    "print(metrics.accuracy_score(y, y_pred_cross))\n",
    "print(\"\")\n",
    "\n",
    "# Si se ejecuta más veces, se ve que la precisión es más estable.\n",
    "\n",
    "# Otra forma: devuelve un array de precisiones de cada conjunto:\n",
    "scores = cross_val_score(clasificador, X, y, cv = 10)\n",
    "print(scores)\n",
    "print(\"\")\n",
    "\n",
    "# Si hacemos la media:\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para usar accuracy_score sin llamar a la librería:\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00, 4.99487439e-16],\n",
       "       [9.99999991e-01, 8.53704616e-09],\n",
       "       [9.99999973e-01, 2.68005572e-08],\n",
       "       [3.01677356e-01, 6.98322644e-01],\n",
       "       [9.99991759e-01, 8.24114569e-06],\n",
       "       [8.05671368e-01, 1.94328632e-01],\n",
       "       [9.99999480e-01, 5.19771382e-07],\n",
       "       [9.85025693e-01, 1.49743070e-02],\n",
       "       [8.94823562e-01, 1.05176438e-01],\n",
       "       [9.96454734e-01, 3.54526577e-03]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EJERCICIO: calcular las probabilidades de cada clase para todas las instancias y guardarlas en y_pred_prob\n",
    "y_pred_prob = cross_val_predict(clasificador, X, y, cv=10, method = \"predict_proba\")\n",
    "y_pred_prob[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# EJERCICIO: mostrar con un histograma la distribución de la probabilidad de pertenecer a la clase 1 \n",
    "y_pred_proba_1 = pd.Series(y_pred_prob[:,1]) # Predicción del ejercicio anterior\n",
    "y_pred_proba_1.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Métricas de evaluación <a name=\"metricas_clf\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de esta sección trabajaremos sobre los resultados de la validación cruzada (mediante las series <code>y</code> e <code>y_pred</code>) aunque el análisis podía haberse hecho perfectamente con una evaluación _train/test_.\n",
    "\n",
    "En el siguiente enlace se puede consultar la evaluación de modelos en sklearn:\n",
    "https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "\n",
    "### 2.1. Matriz de confusión: TP, FP, TN, FN <a name=\"confusion\"> </a>\n",
    "\n",
    "La matriz de confusión muestra el número de veces que se han producido los distintos tipos de aciertos y fallos. En una clasificación binaria tiene cuatro celdas que suelen denominarse con los siguientes nombres:\n",
    "- TP: _true positives_\n",
    "- TN: _true negatives_\n",
    "- FP: _false positives_\n",
    "- FN: _false negatives_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Accuracy = (TP + TN) / N\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred0</th>\n",
       "      <th>Pred1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True0</th>\n",
       "      <td>194</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True1</th>\n",
       "      <td>11</td>\n",
       "      <td>346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pred0  Pred1\n",
       "True0    194     18\n",
       "True1     11    346"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EJERCICIO: crear la matriz de confusión a partir de 'y' e 'y_pred' en un DataFrame con esta estructura:\n",
    "#   - Columnas: [Predicted 0, Predicted 1]\n",
    "#   - Índice: [True 0,True 1]\n",
    "# Usamos y_pred_cross, que es la ultima evaluación cruzada hecha.\n",
    "\n",
    "cm = pd.DataFrame(metrics.confusion_matrix(y, y_pred_cross), columns = [\"Pred0\", \"Pred1\"], index = [\"True0\", \"True1\"])\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# EJERCICIO: mostrar la matriz de confusión mediante un mapa de calor de Seaborn\n",
    "sns.heatmap(cm, annot = True, fmt = \"d\", cmap = \"Blues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Precisión = TP / (TP + FP)\n",
    "\n",
    "Cobertura (o recall) = TP / (TP + FN)\n",
    "\n",
    "F1 = (2 * Precisión * Cobertura) / (Precisión + Cobertura)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "346\n",
      "18\n",
      "194\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "# EJERCICIO: calcular TP, FP, TN y FN a partir de la matriz de confusión anterior\n",
    "#cm = metrics.confusion_matrix(y, y_pred)\n",
    "# Accedemos con iloc si usamos el dataframe anterior:\n",
    "TP = cm.iloc[1,1]\n",
    "FP = cm.iloc[0,1]\n",
    "TN = cm.iloc[0,0]\n",
    "FN = cm.iloc[1,0]\n",
    "\n",
    "print(str(TP))\n",
    "print(str(FP))\n",
    "print(str(TN))\n",
    "print(str(FN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.9463414634146341,\n",
       "  'recall': 0.9150943396226415,\n",
       "  'f1-score': 0.9304556354916067,\n",
       "  'support': 212},\n",
       " '1': {'precision': 0.9505494505494505,\n",
       "  'recall': 0.969187675070028,\n",
       "  'f1-score': 0.9597780859916782,\n",
       "  'support': 357},\n",
       " 'accuracy': 0.9490333919156415,\n",
       " 'macro avg': {'precision': 0.9484454569820423,\n",
       "  'recall': 0.9421410073463348,\n",
       "  'f1-score': 0.9451168607416425,\n",
       "  'support': 569},\n",
       " 'weighted avg': {'precision': 0.9489816240598529,\n",
       "  'recall': 0.9490333919156415,\n",
       "  'f1-score': 0.9488530253484179,\n",
       "  'support': 569}}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"Invertir la clasificación\": calcular la precisión para la clase negativa:\n",
    "metrics.classification_report(y, y_pred_cross, output_dict = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una de las métricas más usadas es el _accuracy_ que mide directamente el porcentaje de aciertos. Si el dataset está balanceado es un buen indicador, pero si alguna de las clases es muy mayoritaria (o minoritaria) la información que nos dá la métrica puede ser bastante engañosa. En las siguientes secciones veremos otras métricas que son menos sensibles a datasets mal balanceados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Precisión, cobertura y f1 <a name=\"pcf1\"> </a>\n",
    "\n",
    "El siguiente paquete de métricas es el formado por la precisión, cobertura (_recall_) y medida f1. Son métricas que dan diferente importancia al tipo de error (p.e. falsos positivos o falsos negativos en clasificación binaria). Pueden ser de utilidad para sistemas en los que nos preocupan más unos errores que otros: por ejemplo, es menos grave dejar pasar un correo _spam_ que eliminar un correo correcto. El significado intuitivo de las métricas es el siguiente:\n",
    "- _precision_: grado de acierto en las instancias propuestas como positivas (¿son todos los que están?)\n",
    "- _recall_: porcentaje de recuperación del total de las instancias positivas (¿están todos los que son?)\n",
    "- _f1_ : media armónica de precisión y cobertura.\n",
    "\n",
    "Al combinar dos métricas complementarias, la medida _f1_ es apropiada para datasets que no estén bien balanceados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "# Volvemos a usar y_pred_cross como ultima predicción cruzada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9505494505494505\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9505494505494505"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EJERCICIO: calcular la medida 'precisión' a partir de 'y' e 'y_pred'\n",
    "pr = TP / (TP + FP)\n",
    "print(pr)\n",
    "\n",
    "# Comparación con la precisión de metrics:\n",
    "metrics.precision_score(y, y_pred_cross)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.969187675070028"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EJERCICIO: calcular la medida 'cobertura' a partir de 'y' e 'y_pred'\n",
    "recall_score(y, y_pred_cross)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9597780859916782"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EJERCICIO: calcular la medida 'f1' a partir de 'y' e 'y_pred'\n",
    "f1_score(y, y_pred_cross)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Experimentos de clasificación <a name=\"clasificadores\"> </a>\n",
    "\n",
    "En esta sección veremos algunas técnicas más de clasificación de la oferta de sklearn. Para comparar los distintos métodos, almacenaremos los resultados en el siguiente dataframe con tres columnas, dos de ellas serán métricas (_accuracy_ y _f1_) y la última el tiempo de ejecución:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACCURACY</th>\n",
       "      <th>F1</th>\n",
       "      <th>TIEMPO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ACCURACY, F1, TIEMPO]\n",
       "Index: []"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DataFrame donde iremos guardando los resultados de los experimentos\n",
    "RESULTADOS_CLF = pd.DataFrame(columns=['ACCURACY', 'F1', 'TIEMPO'])\n",
    "RESULTADOS_CLF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: implementar la función 'experimento_clf' que encapsule todos los pasos de un experimento de clasificación\n",
    "#    PARÁMETROS DE ENTRADA:\n",
    "#       - clasificador: estimador usado en el experimento\n",
    "#       - X: matriz de atributos\n",
    "#       - y: vector de salida\n",
    "#    SALIDAS:\n",
    "#       - Tupla (accuracy, f1, tiempo) con las métricas del experimento y el tiempo invertido en segundos\n",
    "def experimento_clf(clasificador, X, y):\n",
    "    \n",
    "    # Tiempo inicio:\n",
    "    tini = time.time()\n",
    "    \n",
    "    # Precisión, f1:\n",
    "    y_pred = cross_val_predict(clasificador, X, y)\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    f1 = f1_score(y, y_pred)\n",
    "    \n",
    "    # Tiempo fin:\n",
    "    tfin = time.time()\n",
    "    \n",
    "    return (accuracy, f1, tfin - tini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: usar la función 'experimento_clasificacion' con los siguientes clasificadores y almacenar los resultados \n",
    "#            en el dataframe RESULTADOS_CLF:\n",
    "# - Regresión logística\n",
    "# - Vecinos más cercanos, con k=3 y k=5\n",
    "# - Árbol de decisión\n",
    "# - Gradient boosting\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "RESULTADOS_CLF.loc['LogRegr'] = experimento_clf(LogisticRegression(solver=\"liblinear\"), X, y)\n",
    "RESULTADOS_CLF.loc['Kneigh-3'] = experimento_clf(KNeighborsClassifier(3), X, y)\n",
    "RESULTADOS_CLF.loc['Kneigh-5'] = experimento_clf(KNeighborsClassifier(5), X, y)\n",
    "RESULTADOS_CLF.loc['DTree'] = experimento_clf(DecisionTreeClassifier(), X, y)\n",
    "RESULTADOS_CLF.loc['GBoost'] = experimento_clf(GradientBoostingClassifier(), X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACCURACY</th>\n",
       "      <th>F1</th>\n",
       "      <th>TIEMPO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogRegr</th>\n",
       "      <td>0.950791</td>\n",
       "      <td>0.961219</td>\n",
       "      <td>0.056031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kneigh-3</th>\n",
       "      <td>0.919156</td>\n",
       "      <td>0.936639</td>\n",
       "      <td>0.043969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kneigh-5</th>\n",
       "      <td>0.927944</td>\n",
       "      <td>0.943604</td>\n",
       "      <td>0.047995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DTree</th>\n",
       "      <td>0.919156</td>\n",
       "      <td>0.934844</td>\n",
       "      <td>0.066998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GBoost</th>\n",
       "      <td>0.957821</td>\n",
       "      <td>0.966480</td>\n",
       "      <td>2.002748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ACCURACY        F1    TIEMPO\n",
       "LogRegr   0.950791  0.961219  0.056031\n",
       "Kneigh-3  0.919156  0.936639  0.043969\n",
       "Kneigh-5  0.927944  0.943604  0.047995\n",
       "DTree     0.919156  0.934844  0.066998\n",
       "GBoost    0.957821  0.966480  2.002748"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RESULTADOS_CLF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Entrenamiento de un regresor <a name=\"entrenamiento_reg\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos el dataset _concrete_, disponible en el repositorio UCI. El dataset contiene 1030 registros correspondientes a medidas de resistencia de hormigón. Los atributos se corresponden con las proporciones de la mezcla distintas muestras de hormigón y la edad (en días) de la muestra. La variable numérica a predecir es la resistencia de cada muestra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>Blast Furnace Slag</th>\n",
       "      <th>Fly Ash</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>Coarse Aggregate</th>\n",
       "      <th>Fine Aggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>Concrete compressive strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n",
       "0   540.0                 0.0      0.0  162.0               2.5   \n",
       "1   540.0                 0.0      0.0  162.0               2.5   \n",
       "2   332.5               142.5      0.0  228.0               0.0   \n",
       "3   332.5               142.5      0.0  228.0               0.0   \n",
       "4   198.6               132.4      0.0  192.0               0.0   \n",
       "\n",
       "   Coarse Aggregate  Fine Aggregate  Age  Concrete compressive strength  \n",
       "0            1040.0           676.0   28                          79.99  \n",
       "1            1055.0           676.0   28                          61.89  \n",
       "2             932.0           594.0  270                          40.27  \n",
       "3             932.0           594.0  365                          41.05  \n",
       "4             978.4           825.5  360                          44.30  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EJERCICIO: leer el fichero 'concrete.csv' y crear el dataframe 'X' para los atributos, y la serie 'y' para la clase (atributo 'Concrete compressive strength')\n",
    "DATOS_CONCRETE = pd.read_csv('./Conwcrete.csv')\n",
    "DATOS_CONCRETE.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos \"Concrete compressive strength\" de X, lo ponemos en y:\n",
    "X = DATOS_CONCRETE.drop(['Concrete compressive strength'], axis = 1)\n",
    "y = DATOS_CONCRETE['Concrete compressive strength']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1030 entries, 0 to 1029\n",
      "Data columns (total 8 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Cement              1030 non-null   float64\n",
      " 1   Blast Furnace Slag  1030 non-null   float64\n",
      " 2   Fly Ash             1030 non-null   float64\n",
      " 3   Water               1030 non-null   float64\n",
      " 4   Superplasticizer    1030 non-null   float64\n",
      " 5   Coarse Aggregate    1030 non-null   float64\n",
      " 6   Fine Aggregate      1030 non-null   float64\n",
      " 7   Age                 1030 non-null   int64  \n",
      "dtypes: float64(7), int64(1)\n",
      "memory usage: 64.5 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0       79.99\n",
       "1       61.89\n",
       "2       40.27\n",
       "3       41.05\n",
       "4       44.30\n",
       "        ...  \n",
       "1025    44.28\n",
       "1026    31.18\n",
       "1027    23.70\n",
       "1028    32.77\n",
       "1029    32.40\n",
       "Name: Concrete compressive strength, Length: 1030, dtype: float64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.info()\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenar un regresor es muy simple en Sklearn, basta con crear un objeto del estimador que queramos entrenar y ejecutar el método <code>fit</code>. En este notebook usaremos uno de los regresores más comunes: <code>LinearRegression</code>.\n",
    "\n",
    "### 3.1 ¿Qué es la regresión lineal? <a name=\"regresion_lineal\"> </a>\n",
    "\n",
    "Es un modelo matemático usado para aproximar la relación entre una variable dependiente $y$, y las variables independientes $x_i$. El modelo se expresa con la siguiente fórmula:\n",
    "\n",
    "$$\n",
    "y \\approx \\alpha+\\beta_1x_1+\\beta_2x_2...+\\beta_nx_n\n",
    "$$\n",
    "\n",
    "Sklearn proporciona distinos métodos para realizar regresión lineal. El más simple de ellos es el de los _mínimos cuadrados_ que es el que implementa el estimador <code>LinearRegression</code>. La técnica de los mínimos cuadrados se utiliza para determinar los coeficientes de una función de regresión que minimicen la suma de los cuadrados de los errores. Para una función de regresión lineal, se trataría de minimizar esta expresión:\n",
    "\n",
    "$$\n",
    "S = \\sum (y - f(X))^2 = \\sum (y - \\alpha+\\beta_1x_1+\\beta_2x_2...+\\beta_nx_n)^2\n",
    "$$\n",
    "\n",
    "\n",
    "### 3.2 El estimador <code>LinearRegression</code> <a name=\"estimador_reg_lin\"> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: crear un estimador de la clase LinearRegression y entrenarlo con el dataset <X,y>\n",
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez entrenado un estimador, podemos usarlo para predecir la clase de un conjunto de instancias con el método <code>predict</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: predecir la salida de los primeros 10 valores de X con el regresor entrenado anteriormente\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: dividir el dataset <X, y> en dos datasets <X_train, y_train> y <X_test, y_test> con una distribución 80%-20%,\n",
    "#            entrenar el regresor con <X_train, y_train> y calcular la métrica r2 con <X_test, y_test>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos aplicar validación cruzada para evaluar. Por defecto la métrica de evaluación es <code>r2_score</code> aunque, como veremos en la siguiente sección, hay más métricas implementadas en Sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: predecir la salida de todas las instancias mediante validación cruzada y guardar las prediccciones en y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: calcular el score por defecto sobre todas las instancias mediante validación cruzada\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Métricas de evaluación <a name=\"metricas_reg\"> </a>\n",
    "\n",
    "En las tareas de clasificación las métricas de evaluación se basan en el número de aciertos de las predicciones. En la regresión, sin embargo, no se puede hablar de aciertos ya que las predicciones son numéricas y es muy improbable predecir exactamente el valor correcto. Lo importante para evaluar un regresor es medir la diferencia entre el valor real y el valor predicho. \n",
    "\n",
    "En el siguiente enlace se puede consultar la evaluación de modelos en sklearn:\n",
    "https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "\n",
    "### 4.1. Coeficiente r2 <a name=\"r2\"> </a>\n",
    "R2, o también conocido como coeficiente de determinación, es un coeficente normalizado (entre $-1$ a $1$) que determina la calidad de un modelo para replicar los resultados obsrevados. Se calcula con la siguiente fórmula: \n",
    "$$\n",
    "R2 = 1 - \\frac{\\sum (y -f(X))^2}{\\sum (\\bar{y} - y)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: dadas los siguientes vectores 'y_real' e 'y_pred' calcular la métrica R2\n",
    "#    y_real = [1,   0.5, 1.5, 0]\n",
    "#    y_pred = [1.5, 0,   1.5,  1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: calcular la métrica  R2 usando 'cross_val_score' y el estimador LinearRegression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. MAE <a name=\"mae\"> </a>\n",
    "\n",
    "En la métrica MAE (_mean absolute error_) el error se calcula con la media de las diferencias absolutas entre los valores observados y las predicciones. Es una métrica lineal que se puede interpretar en términos de la magnitud a predecir. Se calcula con la siguiente fórmula: \n",
    "\n",
    "$$\n",
    "MAE = \\frac{\\sum |\\;y -f(X)\\;|}{n}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: dadas los siguientes vectores 'y_real' e 'y_pred' calcular la métrica MAE\n",
    "#    y_real = [1,   0.5, 1.5, 0]\n",
    "#    y_pred = [1.5, 0,   1.5,  1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: calcular la métrica MAE usando 'cross_val_score' y el estimador LinearRegression\n",
    "# NOTA: los scores de MAE son negativos para que los valores altos se correspondan con mejores resultados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Experimentos de regresión <a name=\"regresores\"> </a>\n",
    "\n",
    "En esta sección veremos algunas técnicas más de regresión de la oferta de sklearn. Para comparar los distintos métodos, almacenaremos los resultados en el siguiente dataframe con tres columnas, dos de ellas serán métricas (_accuracy_ y _f1_) y la última el tiempo de ejecución:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame donde iremos guardando los resultados de los experimentos\n",
    "RESULTADOS_REG = pd.DataFrame(columns=['R2', 'MAE', 'TIEMPO'])\n",
    "RESULTADOS_REG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: implementar la función 'experimento_regresion' que encapsule todos los pasos del experimento de la sección anterior\n",
    "#    PARÁMETROS DE ENTRADA:\n",
    "#       - regresor: estimador usado en el experimento\n",
    "#       - X: matriz de atributos\n",
    "#       - y: vector de salida\n",
    "#    SALIDAS:\n",
    "#       - Devolver la tupla (r2, mae, tiempo) con la puntuación del experimento y el tiempo invertido en segundos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EJERCICIO: usar la función 'experimento_regresion' con los siguientes regresores y almacenar los resultados \n",
    "#            en el dataframe RESULTADOS_REG:\n",
    "# - Regresión lineal\n",
    "# - Vecinos más cercanos, con k=3\n",
    "# - Vecinos más cercanos, con k=5\n",
    "# - Árbol de decisión\n",
    "# - Gradient boosting\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
